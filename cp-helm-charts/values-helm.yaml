## ------------------------------------------------------
## Kafka Connect
## ------------------------------------------------------
replicaCount: 1
enabled: true
# image: confluentinc/cp-kafka-connect
# imageTag: 5.5.0
image: alecpowell18/cp-kafka-connect-datagen
imageTag: 0.1
## Optionally specify an array of imagePullSecrets. Secrets must be manually created in the namespace.
## https://kubernetes.io/docs/concepts/containers/images/#specifying-imagepullsecrets-on-a-pod
imagePullSecrets:
#  - name: "regcred"
configurationOverrides:
  "plugin.path": "/usr/share/java,/usr/share/confluent-hub-components"
  "key.converter": "org.apache.kafka.connect.storage.StringConverter"
  "value.converter": "org.apache.kafka.connect.json.JsonConverter"
  "key.converter.schemas.enable": "false"
  "value.converter.schemas.enable": "false"
  "internal.key.converter": "org.apache.kafka.connect.json.JsonConverter"
  "internal.value.converter": "org.apache.kafka.connect.json.JsonConverter"
  "config.storage.replication.factor": "3"
  "offset.storage.replication.factor": "3"
  "status.storage.replication.factor": "3"
  "group.id": "connect-tutorial"
  "config.storage.topic": "connect-configs"
  "offset.storage.topic": "connect-offsets"
  "status.storage.topic": "connect-status"
  "replication.factor": "3"
  "log4j.root.loglevel": INFO
  "log4j.loggers": "org.reflections=ERROR"
  "classpath": "/usr/share/java/monitoring-interceptors/monitoring-interceptors-5.0.1.jar"
  "request.timeout.ms": "20000"
  "retry.backoff.ms": "500"
  # connect worker
  "security.protocol": "SASL_SSL"
  "sasl.jaas.config": "org.apache.kafka.common.security.plain.PlainLoginModule required username='HFAYOJRRZXQIOOHH' password='TLRe5tioYiychyyED0S25kk/WwQNOgl6hqUii6rr7naQ3vS8AmOeKP84HrVPY1c3';"
  "sasl.mechanism": "PLAIN"
  "ssl.endpoint.identification.algorithm": "HTTPS"
  # connect producer
  "producer.security.protocol": SASL_SSL
  "producer.sasl.jaas.config": "org.apache.kafka.common.security.plain.PlainLoginModule required username='HFAYOJRRZXQIOOHH' password='TLRe5tioYiychyyED0S25kk/WwQNOgl6hqUii6rr7naQ3vS8AmOeKP84HrVPY1c3';"
  "producer.sasl.mechanism": PLAIN
  "producer.interceptor.classes": "io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor"
  "producer.confluent.monitoring.interceptor.security.protocol": SASL_SSL
  "producer.confluent.monitoring.interceptor.sasl.jaas.config": "org.apache.kafka.common.security.plain.PlainLoginModule required username='HFAYOJRRZXQIOOHH' password='TLRe5tioYiychyyED0S25kk/WwQNOgl6hqUii6rr7naQ3vS8AmOeKP84HrVPY1c3';"
  "producer.confluent.monitoring.interceptor.sasl.mechanism": PLAIN
  # connect consumer
  "consumer.security.protocol": SASL_SSL
  "consumer.sasl.jaas.config": "org.apache.kafka.common.security.plain.PlainLoginModule required username='HFAYOJRRZXQIOOHH' password='TLRe5tioYiychyyED0S25kk/WwQNOgl6hqUii6rr7naQ3vS8AmOeKP84HrVPY1c3';"
  "consumer.sasl.mechanism": PLAIN
  "consumer.interceptor.classes": "io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor"
  "consumer.confluent.monitoring.interceptor.security.protocol": SASL_SSL
  "consumer.confluent.monitoring.interceptor.sasl.jaas.config": "org.apache.kafka.common.security.plain.PlainLoginModule required username='HFAYOJRRZXQIOOHH' password='TLRe5tioYiychyyED0S25kk/WwQNOgl6hqUii6rr7naQ3vS8AmOeKP84HrVPY1c3';"
  "consumer.confluent.monitoring.interceptor.sasl.mechanism": PLAIN

heapOptions: "-Xms512M -Xmx512M"

## Additional env variables
## CUSTOM_SCRIPT_PATH is the path of the custom shell script to be ran mounted in a volume
customEnv:
  # CUSTOM_SCRIPT_PATH: /etc/scripts/create-connectors.sh
  "CONNECT_SECURITY_PROTOCOL": "SASL_SSL"
  "CONNECT_SASL_JAAS_CONFIG": "org.apache.kafka.common.security.plain.PlainLoginModule required username='HFAYOJRRZXQIOOHH' password='TLRe5tioYiychyyED0S25kk/WwQNOgl6hqUii6rr7naQ3vS8AmOeKP84HrVPY1c3';"
  "CONNECT_SASL_MECHANISM": "PLAIN"
  "CONNECT_SSL_ENDPOINT_IDENTIFICATION_ALGORITHM": "HTTPS"

resources: {}
## If you do want to specify resources, uncomment the following lines, adjust them as necessary,
## and remove the curly braces after 'resources:'
  # limits:
  #   cpu: 200m
  #   memory: 256Mi
  # requests:
  #   cpu: 200m
  #   memory: 256Mi
## Custom pod annotations
podAnnotations: {}

## Node labels for pod assignment
## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/
nodeSelector: {}

## Taints to tolerate on node assignment:
## Ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
# tolerations: {}

## Monitoring
## Kafka Connect JMX Settings
## ref: https://kafka.apache.org/documentation/#connect_monitoring
jmx:
  port: 5555

## Prometheus Exporter Configuration
## ref: https://prometheus.io/docs/instrumenting/exporters/
prometheus:
  ## JMX Exporter Configuration
  ## ref: https://github.com/prometheus/jmx_exporter
  jmx:
    enabled: false
    image: solsson/kafka-prometheus-jmx-exporter@sha256
    imageTag: 6f82e2b0464f50da8104acd7363fb9b995001ddff77d248379f8788e78946143
    port: 5556

    ## Resources configuration for the JMX exporter container.
    ## See the `resources` documentation above for details.
    resources: {}

## You can list load balanced service endpoint, or list of all brokers (which is hard in K8s).  e.g.:
## bootstrapServers: "PLAINTEXT://dozing-prawn-kafka-headless:9092"
kafka:
  bootstrapServers: "SASL_SSL://pkc-epwny.eastus.azure.confluent.cloud:9092"

## If the Kafka Chart is disabled a URL and port are required to connect
## e.g. gnoble-panther-cp-schema-registry:8081
cp-schema-registry:
  url: ""

## List of volumeMounts for connect server container
## ref: https://kubernetes.io/docs/concepts/storage/volumes/
# volumeMounts:
#  - name: credentials
#    mountPath: /etc/creds-volume

## List of volumeMounts for connect server container
## ref: https://kubernetes.io/docs/concepts/storage/volumes/
# volumes:
#  - name: credentials
#    secret:
#      secretName: ccloud-api-key 

## Secret with multiple keys to serve the purpose of multiple secrets
## Values for all the keys will be base64 encoded when the Secret is created or updated
## ref: https://kubernetes.io/docs/concepts/configuration/secret/
secrets:
  # username: kafka123
  # password: connect321

## These values are used only when "customEnv.CUSTOM_SCRIPT_PATH" is defined.
## "livenessProbe" is required only for the edge cases where the custom script to be ran takes too much time
## and errors by the ENTRYPOINT are ignored by the container
## As an example such a similar script is added to "cp-helm-charts/examples/create-connectors.sh"
## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/
livenessProbe:
  # httpGet:
  #   path: /connectors
  #   port: 8083
  # initialDelaySeconds: 30
  # periodSeconds: 5
  # failureThreshold: 10
